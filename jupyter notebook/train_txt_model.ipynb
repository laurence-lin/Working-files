{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_txt_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNiKcA11T2UyvXRjgNTKKQG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurence-lin/Working-files/blob/main/train_txt_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcwMODEZmnhT"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import os\r\n",
        "\r\n",
        "from tensorflow.keras.applications import ResNet50\r\n",
        "import cv2\r\n",
        "\r\n",
        "import tensorflow.keras as keras\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras import layers\r\n",
        "import tensorflow as tf\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import time\r\n",
        "import gc\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BOHP_2Dm2hg",
        "outputId": "8cf8f1a4-10c9-4c6b-ae41-5fb7709e0560"
      },
      "source": [
        "!nvidia-smi\r\n",
        "print(tf.test.gpu_device_name())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Feb 17 08:09:20 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlSRwmkXnD8c",
        "outputId": "516a8729-ad9e-4600-ffd6-6b807b3daa80"
      },
      "source": [
        "from google.colab import drive\r\n",
        "\r\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76-xoJ6Dxv3Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eff49f16-84b1-49fd-ad3c-ef47f9d42f00"
      },
      "source": [
        "# HYPER PARAMETERS SETTING\r\n",
        "\r\n",
        "# Calculate width-height ratio to resize image with same scaling\r\n",
        "img1 = '/content/drive/MyDrive/binary/overlap'\r\n",
        "img1 = os.path.join(img1, os.listdir(img1)[20])\r\n",
        "img1 = plt.imread(img1)\r\n",
        "h2w_ratio = img1.shape[1]/img1.shape[0] # height-to-width ratio\r\n",
        "\r\n",
        "IMAGE_HEIGHT = 500\r\n",
        "IMAGE_WIDTH = int(IMAGE_HEIGHT * h2w_ratio)\r\n",
        "BATCH_SIZE = 1\r\n",
        "FREEZE_LAYER = 2\r\n",
        "CLASSES = 2\r\n",
        "\r\n",
        "OUTPUT_SIZE = 1\r\n",
        "\r\n",
        "# Resize scaling: (width, height)\r\n",
        "img1 = cv2.resize(img1, (IMAGE_WIDTH, IMAGE_HEIGHT))\r\n",
        "img1.shape\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 522, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiIDjAzqoXOx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f96b4d5-3a48-4adc-92b7-4f3e4a17dc9e"
      },
      "source": [
        "\r\n",
        "# Define model\r\n",
        "base_model = ResNet50(\r\n",
        "    include_top = False,\r\n",
        "    input_shape = (IMAGE_HEIGHT, IMAGE_WIDTH, 3),\r\n",
        "    weights = 'imagenet'\r\n",
        "    )\r\n",
        "\r\n",
        "def build_model(base_model):\r\n",
        "    # Build custom model for the pre-trained resnet50\r\n",
        "    \r\n",
        "    x = base_model.output\r\n",
        "    x = keras.layers.Flatten()(x)\r\n",
        "    x = keras.layers.Dropout(0.5)(x)\r\n",
        "    \r\n",
        "    output = keras.layers.Dense(OUTPUT_SIZE, activation = 'softmax', name='softmax')(x)\r\n",
        "    \r\n",
        "    final_model = keras.Model(inputs = base_model.input, \r\n",
        "                        outputs = output)\r\n",
        "    \r\n",
        "    for layer in final_model.layers[:FREEZE_LAYER]:\r\n",
        "        layer.trainable = False\r\n",
        "        \r\n",
        "    for layer in final_model.layers[FREEZE_LAYER:]:\r\n",
        "        layer.trainable = True\r\n",
        "    \r\n",
        "    return final_model\r\n",
        "    \r\n",
        "model = build_model(base_model)\r\n",
        "\r\n",
        "del base_model\r\n",
        "gc.collect()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1384"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "speZ-s_AHpa9"
      },
      "source": [
        "# Vefity the training feature is valid for classification:\r\n",
        "'''\r\n",
        "\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "import glob\r\n",
        "\r\n",
        "src_path = '/content/drive/MyDrive/binary_test'\r\n",
        "\r\n",
        "def preprocess_img(img):\r\n",
        "  '''\r\n",
        "  #img: input image directory\r\n",
        "  #output: processed image array could feed to predictive model\r\n",
        "\r\n",
        "  '''\r\n",
        "\r\n",
        "  img1 = plt.imread(img)\r\n",
        "  img1 = cv2.resize(img1, (IMAGE_WIDTH, IMAGE_HEIGHT))\r\n",
        "  img1 = cv2.cvtColor(img1, cv2.COLOR_RGBA2RGB)\r\n",
        "  #img1 = np.expand_dims(img1, axis = 0)\r\n",
        "\r\n",
        "  return img1\r\n",
        "\r\n",
        "# data\r\n",
        "img_list = list(glob.glob('{}/normal/*.png'.format(src_path)))\r\n",
        "img_list.extend(list(glob.glob('{}/overlap/*.png'.format(src_path))))\r\n",
        "\r\n",
        "\r\n",
        "img_arr_list = []\r\n",
        "label_list = []\r\n",
        "for img in img_list:\r\n",
        "  img_i = preprocess_img(img)\r\n",
        "  print('Preprocess image shape:', img_i.shape)\r\n",
        "  img_i = img_i.flatten()\r\n",
        "  img_arr_list.append(img_i)\r\n",
        "\r\n",
        "  del img_i\r\n",
        "  gc.collect()\r\n",
        "\r\n",
        "images = np.array(img_arr_list)\r\n",
        "print(images.shape)\r\n",
        "\r\n",
        "\r\n",
        "#images = np.concatenate((img1, img2), axis=0)\r\n",
        "labels = np.array([0, 0, 1, 1]).reshape(4, -1)\r\n",
        "\r\n",
        "print(images.shape)\r\n",
        "print(labels.shape)\r\n",
        "\r\n",
        "# model: logistic regression\r\n",
        "lr = LogisticRegression()\r\n",
        "lr.fit(images, labels)\r\n",
        "\r\n",
        "print('Model training finished.')\r\n",
        "\r\n",
        "gc.collect()\r\n",
        "\r\n",
        "prediction = lr.predict(images)\r\n",
        "\r\n",
        "print('Showing the prediction result...')\r\n",
        "for i in range(images.shape[0]):\r\n",
        "  image = images[i].reshape(500, 522, 3)\r\n",
        "  plt.imshow(image)\r\n",
        "  plt.title('Class: {}'.format(prediction[i]))\r\n",
        "\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "3qSYafoQ8mK4",
        "outputId": "c6eac61f-59b1-4e64-de90-4b6342b7319d"
      },
      "source": [
        "\r\n",
        "# Apply other model for classification\r\n",
        "import glob\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.linear_model import SGDClassifier\r\n",
        "\r\n",
        "def preprocess_img(img):\r\n",
        "  '''\r\n",
        "  img: input image directory\r\n",
        "  output: processed image array could feed to predictive model\r\n",
        "\r\n",
        "  '''\r\n",
        "\r\n",
        "  img1 = plt.imread(img)\r\n",
        "  img1 = cv2.cvtColor(img1, cv2.COLOR_RGBA2RGB)\r\n",
        "  img1 = img1.flatten()\r\n",
        "\r\n",
        "  return img1\r\n",
        "\r\n",
        "\r\n",
        "normal_list = glob.glob('/content/drive/MyDrive/binary/normal/*.png')\r\n",
        "overlap_list = glob.glob('/content/drive/MyDrive/binary/overlap/*.png')\r\n",
        "\r\n",
        "images = normal_list + overlap_list\r\n",
        "labels = np.concatenate(( np.zeros((len(normal_list))), np.ones((len(overlap_list)))), axis = 0)\r\n",
        "\r\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(images, labels, test_size = 0.2, stratify = labels)\r\n",
        "\r\n",
        "print('Train size:', len(x_train))\r\n",
        "print('Validate size:', len(x_valid))\r\n",
        "print('Start training...')\r\n",
        "'''\r\n",
        "# Define batch\r\n",
        "BATCH_SIZE = 10\r\n",
        "class_label = np.array([0, 1])\r\n",
        "num_of_batch = int(len(x_train)//BATCH_SIZE) + 1\r\n",
        "\r\n",
        "# Define model\r\n",
        "model = SGDClassifier(loss='hinge', verbosity=1)\r\n",
        "\r\n",
        "# Training\r\n",
        "for i in range(num_of_batch):\r\n",
        "\r\n",
        "  try:\r\n",
        "    img_batch = x_train[i*BATCH_SIZE:(i+1)*(BATCH_SIZE)]\r\n",
        "    label_batch = y_train[i*BATCH_SIZE:(i+1)*(BATCH_SIZE)]\r\n",
        "  except:\r\n",
        "    img_batch = x_train[i*BATCH_SIZE:]\r\n",
        "    label_batch = y_train[i*BATCH_SIZE:]\r\n",
        "\r\n",
        "  img_arr_batch = []\r\n",
        "  for img in img_batch:\r\n",
        "    img_arr = preprocess_img(img)\r\n",
        "    img_arr_batch.append(img_arr)\r\n",
        "\r\n",
        "  img_arr_batch = np.array(img_arr_batch)\r\n",
        "\r\n",
        "  print('Training batch: {}'.format(i + 1))\r\n",
        "\r\n",
        "  # Apply sample weight to overlap samples to increase predict probability\r\n",
        "  model.partial_fit(img_arr_batch, label_batch, classes=class_label)\r\n",
        "\r\n",
        "  del img_batch, label_batch, img_arr, img_arr_batch\r\n",
        "  gc.collect()\r\n",
        "\r\n",
        "print('Finished training.')\r\n",
        "\r\n",
        "# Save pre-trained model as pickle binary file\r\n",
        "\r\n",
        "import pickle\r\n",
        "\r\n",
        "print('Saving model...')\r\n",
        "with open('model.pickle', 'wb') as f:\r\n",
        "   pickle.dump(model, f)\r\n",
        "\r\n",
        "print('Model is saved.')\r\n",
        "'''"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 1534\n",
            "Validate size: 384\n",
            "Start training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# Define batch\\nBATCH_SIZE = 10\\nclass_label = np.array([0, 1])\\nnum_of_batch = int(len(x_train)//BATCH_SIZE) + 1\\n\\n# Define model\\nmodel = SGDClassifier(loss='hinge', verbosity=1)\\n\\n# Training\\nfor i in range(num_of_batch):\\n\\n  try:\\n    img_batch = x_train[i*BATCH_SIZE:(i+1)*(BATCH_SIZE)]\\n    label_batch = y_train[i*BATCH_SIZE:(i+1)*(BATCH_SIZE)]\\n  except:\\n    img_batch = x_train[i*BATCH_SIZE:]\\n    label_batch = y_train[i*BATCH_SIZE:]\\n\\n  img_arr_batch = []\\n  for img in img_batch:\\n    img_arr = preprocess_img(img)\\n    img_arr_batch.append(img_arr)\\n\\n  img_arr_batch = np.array(img_arr_batch)\\n\\n  print('Training batch: {}'.format(i + 1))\\n\\n  # Apply sample weight to overlap samples to increase predict probability\\n  model.partial_fit(img_arr_batch, label_batch, classes=class_label)\\n\\n  del img_batch, label_batch, img_arr, img_arr_batch\\n  gc.collect()\\n\\nprint('Finished training.')\\n\\n# Save pre-trained model as pickle binary file\\n\\nimport pickle\\n\\nprint('Saving model...')\\nwith open('model.pickle', 'wb') as f:\\n   pickle.dump(model, f)\\n\\nprint('Model is saved.')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha-3Sr8lfOfh"
      },
      "source": [
        "# Validation the model performance\r\n",
        "acc = []\r\n",
        "for j in range(len(x_valid)):\r\n",
        "\r\n",
        "  data = np.reshape(preprocess_img(x_valid[j]), (1, -1))\r\n",
        "  target = y_valid[j]\r\n",
        "\r\n",
        "  prediction = model.predict(data)\r\n",
        "  \r\n",
        "  if prediction == target:\r\n",
        "    acc.append(1)\r\n",
        "\r\n",
        "  elif prediction != target:\r\n",
        "    acc.append(0)\r\n",
        "\r\n",
        "  del data, target\r\n",
        "  gc.collect()\r\n",
        "\r\n",
        "accuracy = sum(acc)/len(acc)\r\n",
        "\r\n",
        "print('Validation accuracy: ', accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "kjf25sAxg0Um",
        "outputId": "1db33a50-9d02-40a0-e4a7-5606a217ec1b"
      },
      "source": [
        "# Testing model performance: prediction result\r\n",
        "# Visualization: Create confusion matrix to observe performance\r\n",
        "from sklearn.metrics import plot_confusion_matrix\r\n",
        "import pickle\r\n",
        "\r\n",
        "with open('model.pickle', 'rb') as f:\r\n",
        "  pre_model = pickle.load(f)\r\n",
        "\r\n",
        "x_valid_arr = []\r\n",
        "for j in range(len(x_valid)):\r\n",
        "\r\n",
        "  img_valid = preprocess_img(x_valid[j])\r\n",
        "  x_valid_arr.append(img_valid)\r\n",
        "\r\n",
        "  del img_valid\r\n",
        "  gc.collect()\r\n",
        "\r\n",
        "x_valid_arr = np.array(x_valid_arr)\r\n",
        "\r\n",
        "fig = plot_confusion_matrix(pre_model, x_valid_arr, y_valid, display_labels=['normal', 'overlap'])\r\n",
        "fig.figure_.suptitle('Confusion matrix for SVM')\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAEjCAYAAACGgkLPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZgdVZ3G8e/b2SALaULHbGQTQhTiECWyOIBBWR1GwA2QARQEYWRXGEUEREEGZXMDQSKgGBZZZTEICCQOARKI7CEs2UgnZCUL2br7N39UNdx0erndXTfd1Xk/z1NPbp2qOnXq3vTvnnvqnFOKCMzMLFtlbV0AM7OOyMHVzKwEHFzNzErAwdXMrAQcXM3MSsDB1cysBBxcNzOStpT0V0nvSbqjFfkcJenhLMvWViTtJWl6C48dKWmapBWSTsu6bJZfDq7tlKSvS5oiaaWkSkkPSdozg6y/AvQDtomIr7Y0k4i4JSL2z6A8JSUpJG3f2D4RMTEiRrbwFOcA/4iIXhHxyxbm8QFJ5ZLGSZqfBuzXJX0/3faapOPqOeZ0SVPS14+n17xznX3uTtPHtraMVhwH13ZI0lnAVcAlJIFwCPBb4JAMsh8KvB4RVRnklXuSOrcyi6HAyxme+0qgJ/BxoDfwReCNdNtNwDH1HHN0uq3W64X7SdoG2ANY2JJyWgtFhJd2tJD8Qa0EvtrIPt1Igu+8dLkK6JZuGwvMBb4LvAtUAt9Mt/0YWAesT89xPHAh8KeCvIcBAXRO178BvAWsAN4GjipIn1Rw3GeAZ4H30n8/U7DtceAnwD/TfB4GKhq4ttryn1NQ/kOBL5AEjSXAuQX77wo8BSxL9/010DXd9mR6LavS6z28IP//AeYDf6xNS4/ZLj3Hp9L1gSRBaWw9ZX0MqAbWpPnvkH5+N6fHzALOA8oK3rN/kgTQxcBP68nzJeDQBt6bbYEqYGhB2o7pZ1pR8F6fn15jpzTtFOCaNG2j6/BSor/lti6AlzofCByY/gF1bmSfi4DJwEeAvsD/AT9Jt41Nj78I6JIGpfeBrdPtF7JhMK27PiwNSJ2BHsByYGS6bQCwU/r6G6TBFegDLCWpQXUGjkzXt0m3Pw68mQafLdP1Sxu4ttryn5+W/4Q0UP0Z6AXsBKwGhqf77wLsnp53GPAqcEZBfgFsX0/+/0vyJbUlBcE13ecE4BWgOzAB+EUjn8XjwLcK1m8G7k3LOozkC+H4gvesCjg1Le+W9eT3e5Ka8DeBEfVs/ztwXsH6z4B76paH5AvsoDTtGZKaq4PrJlzcLND+bAMsisZ/th8FXBQR70bEQpIa6dEF29en29dHxIMktaqWtinWAKMkbRkRlRFR30/g/wBmRMQfI6IqIsYDrwH/WbDPHyLi9YhYDdwOjG7knOuBiyNiPXArUAFcHREr0vO/AuwMEBFTI2Jyet6ZwO+AzxZxTRdExNq0PBuIiOtJfoo/TfKF8sMm8gNAUifgCOAHaVlnApez4WczLyJ+lZZ3o3OTBN5bSGqbr0h6Q9JBBdtvqs1PUhnJ/4WbNsolCfLHSPoYUB4RTxVzDZYdB9f2ZzFQ0URb4ECSn5y1ZqVpH+RRJzi/T9KO1ywRsYrkp/RJQKWkB9I/1qbKU1umQQXr85tRnsURUZ2+rg1ACwq2r649XtIOku5PbwAtJ2mnrmgkb4CFEbGmiX2uB0YBv4qItU3sW6uCpLZd97MpfB/mNJZBRKyOiEsiYheSL9rbgTsk9Ul3uQsYIGl3khp3d+CBerK6C/gcSZD+Y5Hltww5uLY/TwFrSdoZGzKP5EZKrSFpWkusIvkDrdW/cGNETIiI/UhqcK+RBJ2mylNbpndaWKbmuIakXCMiYivgXEBNHNPoVHCSepK0Y98AXFgQ2JqyiKTWXfezKXwfip6GLiJqvyx6AMPTtPeBv5DcsDoauDUi1tVz7PvAQ8DJOLi2CQfXdiYi3iNpb/yNpEMldZfURdJBki5LdxsPnCepr6SKdP8/tfCU04C9JQ2R1Bv4Qe0GSf0kHSKpB0nAX0nyk7quB4Ed0u5jnSUdTnKj5f4Wlqk5epG0C69Ma9Un19m+APhoM/O8GpgSEd8iqRVeW8xBaW37duBiSb0kDQXOohmfjaQfSfq0pK6StgBOJ7lZV9gP9yaSXxRfpv4mgVrnAp9NmydsE3NwbYci4nKSP8rzSG7mzCH5eXdPustPgSnAC8CLwHNpWkvO9XfgtjSvqWwYEMvScswjuYP+WTYOXkTEYuBgkh4Ki0nu9B8cEYtaUqZm+h7wdZJeCNeTXEuhC4GbJC2T9LWmMpN0CMlNxdrrPAv4lKSjiizPqSS/Bt4CJpHciBtX5LGQ1Gz/QFILngfsB/xHRKws2OdJkl4ZcyPi2QYzipgXEZOacW7LkCI8WbaZWdZcczUzKwEHVzOzEnBwNTMrAQdXM7MScHA1MysBB1czsxJwcDUzKwEHVzOzEnBwNTMrAQdXM7MScHA1MysBB1czsxJwcDUzKwEHVzOzEnBwNTMrAQdXM7MScHA1MyuBxp4wulmp6NMphg3u0tbFsGZ4/YXuTe9k7cYaVrEu1jb18MhGHbBPj1i8pLrpHYGpL6ydEBEHtuZ8reHgmho2uAvPTBjc1sWwZjhg4Oi2LoI1w9PxaKvzWLykmmcmDClq304DZjT1iPWScnA1s9wIoKbeBxC3Pw6uZpYbQbA+imsWaGsOrmaWK665mpllLAiqI9q6GEVxcDWzXKnBwdXMLFMBVDu4mpllzzVXM7OMBbDeba5mZtkKws0CZmaZC6jOR2x1cDWz/EhGaOWDg6uZ5YioplVzv2wyDq5mlhvJDS0HVzOzTCX9XB1czcwyV5NRzVXSOOBg4N2IGJWm3QaMTHcpB5ZFxGhJw4BXgenptskRcVJj+Tu4mlluZFxzvRH4NXDzB/lHHF77WtLlwHsF+78ZEUVPIuzgama5EYjqjJ5OFRFPpjXSjUgS8DXgcy3N38/QMrNcqQkVtbTSXsCCiJhRkDZc0vOSnpC0V1MZuOZqZrkRiHXRqdjdKyRNKVi/LiKuK/LYI4HxBeuVwJCIWCxpF+AeSTtFxPKGMnBwNbPcSAYRFP2De1FEjGnuOSR1Br4E7PLBeSPWAmvT11MlvQnsAEypNxMcXM0sZzZBV6x9gdciYm5tgqS+wJKIqJb0UWAE8FZjmbjN1cxyI0JUR1lRS1MkjQeeAkZKmivp+HTTEWzYJACwN/CCpGnAX4CTImJJY/m75mpmuVKTUc01Io5sIP0b9aTdCdzZnPwdXM0sN5IbWvkIW/kopZkZzb6h1aYcXM0sV6o9cYuZWbayHKFVag6uZpYrNUX0BGgPHFzNLDeSiVscXM3MMhWI9cUPf21TDq5mlhsRFDVAoD1wcDWzHFFmgwhKzcHVzHIjcM3VzKwkfEPLzCxjQSYTYW8SDq5mlhvJo7XzEbbyUUozMwDkR2ubmWUt8AgtM7OScM3VzCxjEXLN1cwsa8kNLQ9/NTPLmDyIwMwsa8kNrXy0uebjK8DMLFVNWVFLUySNk/SupJcK0i6U9I6kaenyhYJtP5D0hqTpkg5oKn/XXM0sNzIeoXUj8Gvg5jrpV0bELwoTJO1I8sjtnYCBwCOSdoiI6oYyd83VzHKlhrKilqZExJPAkiJPewhwa0SsjYi3gTeAXRs7wMHVzHIjAtbXlBW1ABWSphQsJxZ5mlMkvZA2G2ydpg0C5hTsMzdNa5CbBcwsN5JmgaLrhIsiYkwzT3EN8BOSe2c/AS4HjmtmHoCDa7ty+ZmDefqRrSivqOK6f0zfaPuKZZ244qzBVM7qRpduNXz3ijkM+9iaVp1z3Vrx89OGMOPF7my1dRXnXjuL/oPXMfWJnoy7ZCBV60XnLsEJP5rH6D1Xtupc1rgxY5dz0k/m0akseGh8H27/db+2LlK7VMoRWhGxoPa1pOuB+9PVd4DBBbtum6Y1qMM3C0iaKamirctRjP0PX8LFt7zV4PZbf9mP7XZazbWPTufsq2dzzfmN/irZwPw5XTn7y9tvlD5hfB96lldz4/+9ypdOWMgNPx0AQO8+1Vx001v87rHkXJedNqT5F2RFKysLvnPJO5x31HBOGDuSfQ5ZxpARrfvi7Ihqu2IVs7SEpAEFq4cBtT0J7gOOkNRN0nBgBPBMY3m16+AqabOqWX9i91X02rrBm4/MntGNndPa45ARa1kwpytLFyZv0aN3bs2pXxjByfuO5OpztqW64Ww28NSE3uz31aRNf6+DlzFtUi8iYPtPrGab/lUADB25hrVryli3Nh/9C/No5CffZ97Mrsyf3Y2q9WU8fm85exzwXlsXqx1KmgWKWZrMSRoPPAWMlDRX0vHAZZJelPQCsA9wJkBEvAzcDrwC/A34TmM9BWATBFdJwyS9Kul6SS9LeljSlpJGS5qcNhzfXdtwLOlxSVdJmgKcnq5fmTZIvyrp05LukjRD0k8LznOPpKnpOYptuM6V4Tuu4Z8P9gbgtee7s2BuVxZVdmH2jG48cW85V947g2semU5ZJ3jsrq2byC2xaH4X+g5cD0CnztBjq2qWL9lweOGkB3qz/ajVdO0W2V6QfWCb/utZOK/rB+uLKrtQMWB9G5ao/apJn6PV1NKUiDgyIgZERJeI2DYiboiIoyPiExHxbxHxxYioLNj/4ojYLiJGRsRDTeW/qWqGI4AjI+IESbcDXwbOAU6NiCckXQRcAJyR7t+1tiFa0n8C6yJijKTTgXuBXUi6ULwp6cqIWAwcFxFLJG0JPCvpzjS9wzj8lAVc86NBnLzvSIZ/fDXbj1pNWRk8P7EXM17szqkHjQRg3RpRvk1S6/zxccPS2pB4950unLxvss+h31rIAUc03Qtl5vQtuOHigVwy/s3SXZhZkZLeAp5boNDbETEtfT0V2A4oj4gn0rSbgDsK9r+tzvH3pf++CLxc+20i6S2SRubFwGmSDkv3G0wS0BsNrmkN90SAIYPafwtEj141fO+qpDdIBBy72470H7qWl57uwX5fXcJx51ZudMwF42YCSZvr5WcM4ed3vrHB9or+61k4L6m9VlfBquWd2KpP8mtn4bwuXHT8MM6+ejYDh60r7cVt5hbP70LfgR++xxUD1rOosksblqh9ytNjXjZVm+vagtfVQHkT+69q4PiaOnnVAJ0ljQX2BfaIiJ2B54EtmipURFwXEWMiYkzfbdr/t+HK9zqxfl3yH+uhP/dh1O4r6dGrhtF7rWDiA+UsW5R8QSxf2okFc4v7w9x9/+X8/Y4+AEy8v5yd91yBlJzrR8d8lOPOrWSnXet+HJa16dO6M2j4OvoNXkvnLjWMPWQZkx/u3dbFapeyahYotbaqrr0HLJW0V0RMBI4GnmjimMb0BpZGxPuSPgbsnkUhN7WfnTyUF57qyXtLOnPULjty9HfnU1WV/Cc5+JjFzJ7RjV+cMQSR3GQ68/KkFjt0h7Uce04lPzhiOyKgU+fglEvm0m/bptvsDjxyMZedNpRvfObj9Cqv4txrZgFw3x8qmPd2V265oj+3XNE/Kd+tb1JeUVWai9/M1VSL3/xwEJf8+S3KOsHDt/Zh1utN1g82O3mauKUtfwsfC1wrqTvwFvDNVuT1N+AkSa8C04HJGZRvk/tBGtgasuOY9xk36bV6t409ZBljD1nW4LH9B6/bqEkAoOsWwXnXzdwo/etnLODrZyzYKN1K59nHtuLZx7Zq62K0e54sOxURM4FRBeuFEyJsVMOMiLENrUfE48DjDex7UAPnH9aM4ppZOxYhqhxczcyy52YBM7OMuc3VzKxEHFzNzDKWp36uDq5mlivtoQ9rMRxczSw3IqCqxr0FzMwy52YBM7OMuc3VzKxEwsHVzCx7vqFlZpaxCLe5mpmVgKh2bwEzs+zlpc01H18BZmZk+/RXSeMkvSvppYK0n0t6reDZfuVp+jBJqyVNS5drm8rfwdXM8iOSdtdiliLcCBxYJ+3vwKiI+DfgdeAHBdvejIjR6XJSU5k7uJpZrmT49NcnSR50Wpj2cETUPm5jMrBtS8vp4GpmuRHpDa1iFqBC0pSC5cRmnu44oPAR2sMlPS/pCUl7NXWwb2iZWa4U+ZMfYFFEjGnJOST9EKgCbkmTKoEhEbFY0i7APZJ2iojlDeXh4GpmuVLq3gKSvgEcDHw+IgnlEbGW9MnTETFV0pvADsCUhvJxcDWz3EhuVpUuuEo6EDgH+GxEvF+Q3hdYEhHVkj4KjCB5sGqDHFzNLFeyGqElaTwwlqRtdi5wAUnvgG7A3yUBTE57BuwNXCRpPVADnBQRS+rNOOXgama50ow21ybyiSPrSb6hgX3vBO5sTv4OrmaWG4Go8fBXM7PsZVRxLTkHVzPLjxLf0MqSg6uZ5UtOqq4OrmaWK7mvuUr6FY18R0TEaSUpkZlZAwKoqcl5cKWRkQdmZm0igLzXXCPipsJ1Sd0LRyyYmbWFrPq5llqTHcYk7SHpFeC1dH1nSb8tecnMzOoTRS5trJjeuFcBBwCLASLiXyRDwczMNjERUdzS1orqLRARc9JxtrWqS1McM7MmtINaaTGKCa5zJH0GCEldgNOBV0tbLDOzegRETnoLFNMscBLwHWAQMA8Yna6bmbUBFbm0rSZrrhGxCDhqE5TFzKxpOWkWKKa3wEcl/VXSwvQxtPemk8WamW16Hai3wJ+B24EBwEDgDmB8KQtlZlav2kEExSxtrJjg2j0i/hgRVenyJ2CLUhfMzKw+yaNeml7aWmNzC/RJXz4k6fvArSTfG4cDD26CspmZbSwnvQUau6E1lSSY1l7Jtwu2BcmzZszMNim1g1ppMRqbW2D4piyImVmTMrxZJWkcySO0342IUWlaH+A2YBgwE/haRCxVMorqauALwPvANyLiucbyL+phNJJGSfqapGNql5ZekJlZyxV5M6u4G1o3AgfWSfs+8GhEjAAeTdcBDiJ5nPYI4ETgmqYyL6Yr1gXAr9JlH+Ay4IvFlNzMLHMZdcWKiCeBuo/HPgSonRHwJuDQgvSbIzEZKJc0oLH8i6m5fgX4PDA/Ir4J7Az0LuI4M7Ps1RS5tEy/iKhMX88H+qWvBwFzCvabm6Y1qJi5BVZHRI2kKklbAe8Cg5tZYDOz1mveZNkVkgon/b8uIq4r+lQRIbX89lkxwXWKpHLgepIeBCuBp1p6QjOz1mhGuFsUEWOamf0CSQMiojL92f9umv4OG1Yqt03TGtRks0BE/HdELIuIa4H9gGPT5gEzs02vtMNf7wOOTV8fC9xbkH6MErsD7xU0H9SrsUEEn2psW1PdEMzM2jNJ44GxJM0Hc4ELgEuB2yUdD8wCvpbu/iBJN6w3SLpiNVnBbKxZ4PJGtgXwuaYyz5PXX+jOAQNHt3UxrBkmzJvW1kWwZtj1gGwewZfVIIKIOLKBTZ+vZ9+gmVOtNjaIYJ/mZGRmVnJBhxj+ambW/uR9+KuZWXuU+7kFzMzapZwE12KGv0rSf0k6P10fImnX0hfNzKweHehJBL8F9gBq76ytAH5TshKZmTVAUfzS1oppFtgtIj4l6XmAdPqtriUul5lZ/TpQb4H1kjqRVrQl9aU10yKYmbVCe6iVFqOYZoFfAncDH5F0MTAJuKSkpTIza0hO2lybrLlGxC2SppKMWhBwaES8WvKSmZnV1U7aU4vRZHCVNIRkLO1fC9MiYnYpC2ZmVq+OElyBB/jwQYVbAMOB6cBOJSyXmVm9lJM7PsU0C3yicD2dLeu/S1YiM7MOoNkjtCLiOUm7laIwZmZN6ijNApLOKlgtAz4FzCtZiczMGtKRbmgBvQpeV5G0wd5ZmuKYmTWhIwTXdPBAr4j43iYqj5lZ4/IeXCV1jogqSf++KQtkZtYQ0TF6CzxD0r46TdJ9wB3AqtqNEXFXictmZrahDtbmugWwmOSZWbX9XQNwcDWzTa8DBNePpD0FXuLDoForJ5dnZh1OBtFH0kjgtoKkjwLnA+XACcDCNP3ciHiwJedoLLh2AnqyYVCt5eBqZm0ii2aBiJgOjIYPbty/QzJB1TeBKyPiF609R2PBtTIiLmrtCczMMpV91e7zwJsRMUvKbq7YxqYczMeMtGa2+Yikt0AxC1AhaUrBcmIDuR4BjC9YP0XSC5LGSdq6pUVtLLh+vqWZmpmVTPHzuS6KiDEFy3V1s0qfqvJFkt5QANcA25E0GVQCl7e0mA02C0TEkpZmamZWKhl3xToIeC4iFgDU/gsg6Xrg/pZmXMyTCMzM2o9sn0RwJAVNApIGFGw7jKS3VIs0e1YsM7M2k+EjXCT1APYDvl2QfJmk0elZZtbZ1iwOrmaWGyK7ZoGIWAVsUyft6Gxyd3A1s5zpSMNfzczaDwdXM7MScHA1M8tYB5sVy8ys/XBwNTPLXkeYLNvMrN1xs4CZWdYyHERQag6uZpYvDq5mZtnKcoRWqTm4mlmuqCYf0dXB1czyw22uZmal4WYBM7NScHA1M8uea65mZqXg4GpmlrHw8Fczs8y5n6uZWalEPqKrg6uZ5UpWNVdJM4EVQDVQFRFjJPUBbgOGkTyg8GsRsbQl+Tu4dlBjxi7npJ/Mo1NZ8ND4Ptz+635tXaQO6fIzB/P0I1tRXlHFdf+YvtH2Fcs6ccVZg6mc1Y0u3Wr47hVzGPaxNa0657q14uenDWHGi93Zausqzr12Fv0Hr2PqEz0Zd8lAqtaLzl2CE340j9F7rmzVudqd7AcR7BMRiwrWvw88GhGXSvp+uv4/Lcm4LIvSbUqSZkqqaOtytGdlZcF3LnmH844azgljR7LPIcsYMqJ1f9BWv/0PX8LFt7zV4PZbf9mP7XZazbWPTufsq2dzzfmDis57/pyunP3l7TdKnzC+Dz3Lq7nx/17lSycs5IafDgCgd59qLrrpLX73WHKuy04b0vwLygHVFLe00CHATenrm4BDW5pRboKrErkpb1sa+cn3mTezK/Nnd6NqfRmP31vOHge819bF6pA+sfsqem1d3eD22TO6sXNaexwyYi0L5nRl6cLkB+Ojd27NqV8Ywcn7juTqc7aluuFsNvDUhN7s99UlAOx18DKmTepFBGz/idVs078KgKEj17B2TRnr1qoVV9c+NSO4VkiaUrCcWCerAB6WNLVgW7+IqExfzwda/JOvpMFK0lmSXkqXMyRdKuk7BdsvlPS99PXZkp6V9IKkH6dpwyRNl3Qz8BIwuE7+96RvzMuFb5yklZKuTNMfldS3lNfZ3mzTfz0L53X9YH1RZRcqBqxvwxJtvobvuIZ/PtgbgNee786CuV1ZVNmF2TO68cS95Vx57wyueWQ6ZZ3gsbu2LirPRfO70Hdg8nl26gw9tqpm+ZJOG+wz6YHebD9qNV275ePmT9GC5IZWMQssiogxBct1dXLbMyI+BRwEfEfS3hucKqJVjRAla3OVtAvwTWA3kh4UTwP/BVwF/Cbd7WvAAZL2B0YAu6b73pde6Ow0/diImJzmW3ia4yJiiaQtgWcl3RkRi4EewJSIOFPS+cAFwCn1lPFE4ESALeie5eWbAXD4KQu45keDOHnfkQz/+Gq2H7WasjJ4fmIvZrzYnVMPGgnAujWifJuk1vnj44alvzrEu+904eR9k30O/dZCDjhiSZPnnDl9C264eCCXjH+zdBfWhrK6oRUR76T/vivpbpL4s0DSgIiolDQAeLel+ZfyhtaewN0RsQpA0l3AXsBHJA0E+gJLI2KOpNOB/YHn02N7kgTV2cCs2sBaj9MkHZa+HpwesxioIbnjB/An4K76Dk6/ya4D2Ep9OsxX/OL5Xeg7cN0H6xUD1rOosksblmjz1aNXDd+7ag6QVKaO3W1H+g9dy0tP92C/ry7huHMrNzrmgnEzgaTN9fIzhvDzO9/YYHtF//UsnJfUXqurYNXyTmzVJ2lTWDivCxcdP4yzr57NwGHr6mbdMWTwlyqpB1AWESvS1/sDFwH3AccCl6b/3tvSc7RFG+YdwFeAw/kwAAr4WUSMTpftI+KGdNuq+jKRNBbYF9gjInYmCcxbNHDODhM4izF9WncGDV9Hv8Fr6dylhrGHLGPyw73bulibpZXvdWL9uuTX1kN/7sOo3VfSo1cNo/dawcQHylm2KKnfLF/aiQVzi/sC3H3/5fz9jj4ATLy/nJ33XIGUnOtHx3yU486tZKdd6/2zyb3aQQTFLE3oB0yS9C/gGeCBiPgbSVDdT9IMkvhyaUvLWsqa60TgRkmXkrwnhwFHA+uA64EK4LPpvhOAn0i6JSJWShoENNVI2Juk5vu+pI8BuxdsKyMJ4LcCXwcmZXRNuVBTLX7zw0Fc8ue3KOsED9/ah1mvN/S9Y63xs5OH8sJTPXlvSWeO2mVHjv7ufKqqkmB68DGLmT2jG784Ywgiucl05uVJLXboDms59pxKfnDEdkRAp87BKZfMpd+2TbeNH3jkYi47bSjf+MzH6VVexbnXzALgvj9UMO/trtxyRX9uuaJ/Ur5b36S8oqo0F98WIjKZLDsi3gJ2rid9MfD5Vp8AUJRwtIOks4Dj0tXfR8RVafqLJI3N+xTsezrwrXR1JUn7bDVwf0SMKthvJjCGpPPvPSSdfacD5cCFEfG4pJUkP/f3J2kzOTwiFjZW1q3UJ3ZTJu+pbSIT5k1r6yJYM+x6wBym/GtNq7ov9CrfNj659+lF7Tvxr+dMjYgxrTlfa5R0EEFEXAFcUU/6J+pJuxq4up5sRtXZb1jB6kGNnPusogtqZrnhuQXMzLIWgJ+h1XYiomdbl8HMSiQfsbVjBlcz67jcLGBmVgJ+tLaZWdb8aG0zs+wlgwjyEV0dXM0sX/wMLTOz7LnmamaWNbe5mpmVQjZzC2wKDq5mli9uFjAzy1i06vlYm5SDq5nli2uuZmYlkI/Y6uBqZvmimny0Czi4mll+BB5EYGaWNRG5GUTQFg8oNDNruYjilkZIGizpH5JekfRy+pgpJF0o6R1J09LlCy0tpmuuZpYv2dRcq4DvRsRzknoBUyX9Pd12ZUT8orUncHA1s/zIqM01IiqByvT1CkmvAoNan/OH3CxgZrmimpqiFqBC0pSC5cR685OGAZ8Enk6TTpH0gqRxkrZuaTkdXM0sR4psb02aDhZFxJiC5bq6uUnqCdwJnBERy4FrgO2A0SQ128tbWlI3C5hZfo67hAMAAAeJSURBVASZjdCS1IUksN4SEXcBRMSCgu3XA/e3NH/XXM0sX2qKXBohScANwKsRcUVB+oCC3Q4DXmppMV1zNbNcyaif678DRwMvSpqWpp0LHClpNEkdeSbw7ZaewMHVzPIlg+AaEZNIHslV14Otzjzl4Gpm+REB1fkY/+rgamb5kpPhrw6uZpYvDq5mZhkLwM/QMjPLWkC4zdXMLFuBb2iZmZWE21zNzErAwdXMLGtNT4TdXji4mll+BOAHFJqZlYBrrmZmWfPwVzOz7AWE+7mamZWAR2iZmZWA21zNzDIW4d4CZmYl4ZqrmVnWgqiubutCFMXB1czyI0dTDvrpr2aWL1FT3NIESQdKmi7pDUnfz7qYrrmaWW4EEBnUXCV1An4D7AfMBZ6VdF9EvNLqzFOuuZpZfkRkVXPdFXgjIt6KiHXArcAhWRbVNVczy5WMbmgNAuYUrM8Fdssi41oOrqkVLF30SPxlVluXowQqgEVtXYhS6DSgrUtQMh31Mxva2gxWsHTCI/GXiiJ330LSlIL16yLiutaWoVgOrqmI6NvWZSgFSVMiYkxbl8OK58+sYRFxYEZZvQMMLljfNk3LjNtczWxz9CwwQtJwSV2BI4D7sjyBa65mttmJiCpJpwATgE7AuIh4OctzOLh2fJusjcky489sE4iIB4EHS5W/IifjdM3M8sRtrmZmJeDgag2SNFNSsd1erAT8GeSXg2sHJcnt6TmmhP8+c8wfXjsmaZikVyVdL+llSQ9L2lLSaEmTJb0g6W5JW6f7Py7pqrTj9Onp+pWSpqT5fFrSXZJmSPppwXnukTQ1PceJbXbBOSfpLEkvpcsZki6V9J2C7RdK+l76+mxJz6af4Y/TtGHpRCI3Ay+xYT/MBj8nSSvTz/llSY9K6pB9tnMnIry00wUYBlQBo9P124H/Al4APpumXQRclb5+HPhtwfGPA/+bvj4dmAcMALqRDPfbJt3WJ/13S5I/6tr0mUBFW78PeViAXYAXgR5AT+Bl4JPAEwX7vEISMPcn6REgkgrO/cDe6eddA+xecMwHn0Ejn1MAR6Wvzwd+3dbvh5dwzTUH3o6IaenrqcB2QHlEPJGm3UTyh1nrtjrH13aMfhF4OSIqI2It8BYf1oxOk/QvYHKaNiLja9gc7AncHRGrImIlcBewF/ARSQMl7QwsjYg5JMF1f+B54DngY3z4ns+KiMkNnKOhz6mGDz/3P6VlsTbmdrn2b23B62qgvIn9VzVwfE2dvGqAzpLGAvsCe0TE+5IeB7ZocWmtrjuArwD9+TAACvhZRPyucEdJw9j486vdNpbiPyf3r2wHXHPNn/eApZL2StePBp5oZP+m9CapUb0v6WPA7q0t4GZqInCopO6SegCHpWm3kQyt/ApJoIVkVNBxknoCSBok6SNN5N/Y51SW5g/wdWBSFhdkreOaaz4dC1wrqTvJz/tvtiKvvwEnSXoVmE7yk9OaKSKek3Qj8Eya9PuIeB5AUi/gnYioTPd9WNLHgackAawkaUtvbC69xj6nVcCuks4D3gUOz+zCrMU8Qsss5yStjIiebV0O25CbBczMSsA1VzOzEnDN1cysBBxczcxKwMHVzKwEHFytKJKqJU1Lx83fkXYDa2leN0r6Svr695J2bGTfsZI+04Jz1DubVDGzTEla2cxzfTBngFktB1cr1uqIGB0Ro4B1wEmFG1s6C1dEfCsiXmlkl7FAs4OrWVtzcLWWmAhsn9YqJ0q6D3hFUidJPy+Y7enb8MH0eb9OZ3x6BPhgNFI6c9eY9PWBkp6T9K90dqdhJEH8zLTWvJekvpLuTM/xrKR/T4/dJp017GVJvycZYtqoxmYDq2+WKUnbSfpbeszEdKSUWb08QsuaJa2hHkQyYgjgU8CoiHg7DVDvRcSnJXUD/inpYZLZoUYCOwL9SGaHGlcn377A9cDeaV59ImKJpGuBlRHxi3S/PwNXRsQkSUNIhpJ+HLgAmBQRF0n6D+D4Ii7nuPQcWwLPSrozIhaTzGw1JSLOlHR+mvcpJDNZnRQRMyTtBvwW+FwL3kbbDDi4WrG2lFQ7O9dE4AaSn+vPRMTbafr+wL/VtqeSjIcfQTJr1/iIqAbmSXqsnvx3B56szSsiljRQjn2BHdNhowBbpWP09wa+lB77gKSlRVzTaZIOS1/XzjK1mI1nmborPcdngDsKzt2tiHPYZsrB1Yq1OiJGFyakQaZwFicBp0bEhDr7fSHDcpSRzHe6pp6yFK0Fs0yVAcvqvgdmDXGbq2VpAnCypC4AknZIZ4h6Ejg8bZMdAOxTz7GTgb0lDU+P7ZOmrwB6Fez3MHBq7Yqk2mD3JMmMUEg6CNi6ibI2a5apiFgOvC3pq+k5pGSOVrN6Obhaln5P0p76nKSXgN+R/Dq6G5iRbrsZeKrugRGxEDiR5Cf4v/jwZ/lfgcNqb2gBpwFj0htmr/Bhr4UfkwTnl0maB2Y3Uda/kcxn+ypwKfXPMvUSSZvqRWn6UcDxafleBg4p4j2xzZTnFjAzKwHXXM3MSsDB1cysBBxczcxKwMHVzKwEHFzNzErAwdXMrAQcXM3MSsDB1cysBP4fxyzcsf0Uhp8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "GqhZs1hHJSyS",
        "outputId": "bc2b5c53-d970-4534-c47e-b4b61e5947d6"
      },
      "source": [
        "print(x_valid_arr.shape)\r\n",
        "print(y_valid.shape)\r\n",
        "\r\n",
        "print(y_valid[0:5])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-762f5b9c8da7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_valid_arr' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocH6jw8TmSEC"
      },
      "source": [
        "\r\n",
        "# Advantage of generator: yields a value everytime someone asks for a new input, save memory\r\n",
        "# Load image by directory folder\r\n",
        "\r\n",
        "img_path = '/content/drive/MyDrive/binary_test'\r\n",
        "class_names = ['normal' , 'overlap']\r\n",
        "\r\n",
        "train_df = keras.preprocessing.image_dataset_from_directory(\r\n",
        "    img_path,\r\n",
        "    #labels = data_label,\r\n",
        "    label_mode = 'binary',\r\n",
        "    class_names = class_names,\r\n",
        "    #validation_split = 0.1,\r\n",
        "    color_mode = 'rgb',\r\n",
        "    #subset = 'training',\r\n",
        "    image_size = (IMAGE_HEIGHT, IMAGE_WIDTH),\r\n",
        "    batch_size = BATCH_SIZE,\r\n",
        "    seed = 123\r\n",
        "    )\r\n",
        "\r\n",
        "'''\r\n",
        "valid_df = keras.preprocessing.image_dataset_from_directory(\r\n",
        "    img_path,\r\n",
        "    #labels = data_label,\r\n",
        "    label_mode = 'binary',\r\n",
        "    class_names = class_names,\r\n",
        "    validation_split = 0.1,\r\n",
        "    color_mode = 'rgb',\r\n",
        "    subset = 'validation',\r\n",
        "    image_size = (IMAGE_HEIGHT, IMAGE_WIDTH),\r\n",
        "    batch_size = BATCH_SIZE,\r\n",
        "    seed = 123\r\n",
        "    )\r\n",
        "\r\n",
        "train_df = train_df.cache().prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n",
        "valid_df = valid_df.cache().prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BI3GvA-Ad61Z"
      },
      "source": [
        "'''\r\n",
        "plt.figure(figsize=(10, 10))\r\n",
        "\r\n",
        "for images, labels in train_df.take(1):\r\n",
        "  print(images.shape)\r\n",
        "\r\n",
        "  for i in range(9):\r\n",
        "    ax = plt.subplot(3, 3, i + 1)\r\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\r\n",
        "    plt.title(int(labels[i]))\r\n",
        "    plt.axis(\"off\")\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4-2xZw2DWsd"
      },
      "source": [
        "# Check image and label pair is matched.\r\n",
        "# Show images from tensorflow datasets: directly show image from dataset might return blank\r\n",
        "# Use visualize functions: tfds.show_examples\r\n",
        "'''\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "class_dict = {'0':'normal', '1':'overlap'}\r\n",
        "\r\n",
        "for images, labels in train_df.take(1):\r\n",
        "\r\n",
        "  images = np.array(images)\r\n",
        "  labels = np.array(labels)\r\n",
        "\r\n",
        "  for i in range(len(images)):\r\n",
        "\r\n",
        "    image = (images[i]).astype(np.uint8)\r\n",
        "    label = int(labels[i][0])\r\n",
        "    img = Image.fromarray(image)\r\n",
        "    label = class_dict[str(label)]\r\n",
        "\r\n",
        "    img.save('{}_num{}.png'.format(label, i))\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OA2Oq_96ntWu"
      },
      "source": [
        "# Data loader for normal image and overlap image\r\n",
        "\r\n",
        "# image_dataset_from_directory parameters:\r\n",
        "# label_mode: int: label is int32 with size(batch_size). binary: label = float32 with size(batch_size, 1). categorical: label=float32 with size(batch_size, num_class)\r\n",
        "# colormode: automatically convert input image to the n_channels. rgb: 3 channel, rgba: 4 channel, grayscale: 1 channel\r\n",
        "\r\n",
        "'''\r\n",
        "import random\r\n",
        "import glob, sys\r\n",
        "\r\n",
        "\r\n",
        "img_list = glob.glob('/content/drive/MyDrive/binary/total_image/*.png')\r\n",
        "\r\n",
        "# Train/validation split\r\n",
        "test_size = 0.2\r\n",
        "test_samples = int(len(img_list)*0.2)\r\n",
        "valid_list = list(random.sample(img_list, test_samples))\r\n",
        "train_list = list(set(img_list) - set(valid_list))\r\n",
        "\r\n",
        "print('Number of train samples: ', len(train_list))\r\n",
        "print('Number of valid samples: ', len(valid_list))\r\n",
        "\r\n",
        "'''\r\n",
        "\r\n",
        "#ImageDataGenerator: generate image from batches of 4D array data, but one generator could fit on train and validation data seperately\r\n",
        "\r\n",
        "'''\r\n",
        "data_gen = keras.preprocessing.image.ImageDataGenerator(\r\n",
        "  horizontal_flip = True,\r\n",
        "  vertical_flip = True\r\n",
        ")\r\n",
        "\r\n",
        "valid_gen = keras.preprocessing.image.ImageDataGenerator(\r\n",
        "  horizontal_flip = True,\r\n",
        "  vertical_flip = True\r\n",
        ")\r\n",
        "\r\n",
        "train_images = []\r\n",
        "for i in range(len(train_list)):\r\n",
        "  img = plt.imread(train_list[i])\r\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)\r\n",
        "  img = cv2.resize(img, (IMAGE_HEIGHT, IMAGE_WIDTH))\r\n",
        "  train_images.append(img)\r\n",
        "\r\n",
        "print('Load train image finished.')\r\n",
        "valid_images = []\r\n",
        "for i in range(len(valid_list)):\r\n",
        "  img = plt.imread(valid_list[i])\r\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)\r\n",
        "  img = cv2.resize(img, (IMAGE_HEIGHT, IMAGE_WIDTH))\r\n",
        "  valid_images.append(img) \r\n",
        "\r\n",
        "print('Load Valid image finished.')\r\n",
        "\r\n",
        "print(train_images[0].dtype)\r\n",
        "print('Size cost of train_images:', (sys.getsizeof(train_images)))\r\n",
        "\r\n",
        "train_images = np.stack(train_images, axis=0)\r\n",
        "valid_images = np.stack(valid_images, axis=0)\r\n",
        "\r\n",
        "print('Fitting train_images..')\r\n",
        "data_gen.fit(train_images)\r\n",
        "gc.collect()\r\n",
        "\r\n",
        "#print('Fitting valid_images..')\r\n",
        "#valid_gen.fit(valid_images)\r\n",
        "\r\n",
        "\r\n",
        "img_path = '/content/drive/MyDrive/binary/total_image'\r\n",
        "\r\n",
        "label_file = pd.DataFrame(columns = ['image', 'label'])\r\n",
        "label_file['image'] = [file for file in os.listdir(img_path) if '.png' in file]\r\n",
        "\r\n",
        "for i in range(len(label_file)):\r\n",
        "    if 'add' in label_file.iloc[i]['image']:\r\n",
        "        label_file.iloc[i]['label'] = 1\r\n",
        "        \r\n",
        "    elif 'text' in label_file.iloc[i]['image']:\r\n",
        "        label_file.iloc[i]['label'] = 0\r\n",
        "\r\n",
        "train_label = []\r\n",
        "valid_label = []\r\n",
        "\r\n",
        "train_order = [file.split('/')[-1] for file in train_list]\r\n",
        "valid_order = [file.split('/')[-1] for file in valid_list]\r\n",
        "\r\n",
        "train_label = label_file.set_index('image').reindex(train_order).reset_index()\r\n",
        "valid_label = label_file.set_index('image').reindex(valid_order).reset_index()\r\n",
        "\r\n",
        "\r\n",
        "train_label = train_label['label']\r\n",
        "valid_label = valid_label['label']\r\n",
        "\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okDzdAhcoaWv"
      },
      "source": [
        "model.compile(\r\n",
        "    optimizer = keras.optimizers.Adam(1e-3),\r\n",
        "    loss = tf.losses.BinaryCrossentropy(from_logits = False), # with softmax as last layer, no logits\r\n",
        "    metrics=['accuracy']\r\n",
        "    )\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7AtP7-sob0e"
      },
      "source": [
        "# datagen.flow: Iterator yield tuples: (input_samples, labels)\r\n",
        "import multiprocessing\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "Iterations = 100\r\n",
        "\r\n",
        "callbacks = keras.callbacks.EarlyStopping(\r\n",
        "    monitor='val_loss',\r\n",
        "    patience = 5,\r\n",
        "    verbose = 2\r\n",
        ")\r\n",
        "\r\n",
        "gc.collect()\r\n",
        "history = model.fit(\r\n",
        "    train_df,\r\n",
        "    #validation_data=valid_df,\r\n",
        "    epochs = Iterations,\r\n",
        "    callbacks = [callbacks],\r\n",
        "    )\r\n",
        "\r\n",
        "\r\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKlZH-VxuqsE"
      },
      "source": [
        "# Save model on drive \r\n",
        "model.save('txt_overlap_model')\r\n",
        "!mkdir /content/drive/MyDrive/save_model\r\n",
        "!cp -r txt_overlap_model '/content/drive/MyDrive/save_model'\r\n",
        "\r\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKdJ7pFv-Dwe"
      },
      "source": [
        "# Clear session\r\n",
        "\r\n",
        "from keras import backend as K\r\n",
        "\r\n",
        "del model, re_model\r\n",
        "K.clear_session()\r\n",
        "\r\n",
        "from numba import cuda\r\n",
        "cuda.select_device(0)\r\n",
        "cuda.close()\r\n",
        "\r\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4OgSPxk6lf2"
      },
      "source": [
        "%cd /content\r\n",
        "\r\n",
        "gc.collect()\r\n",
        "re_model = keras.models.load_model('txt_overlap_model')\r\n",
        "\r\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJRe1xeofQV8"
      },
      "source": [
        "re_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF_8G7Dxh9YB"
      },
      "source": [
        "\r\n",
        "\r\n",
        "def preprocess_img(img):\r\n",
        "  '''\r\n",
        "  img: input image directory\r\n",
        "  output: processed image array could feed to predictive model\r\n",
        "\r\n",
        "  '''\r\n",
        "\r\n",
        "  img1 = plt.imread(img)\r\n",
        "  img1 = cv2.resize(img1, (IMAGE_WIDTH, IMAGE_HEIGHT))\r\n",
        "  img1 = cv2.cvtColor(img1, cv2.COLOR_RGBA2RGB)\r\n",
        "  img1 = np.expand_dims(img1, axis = 0)\r\n",
        "\r\n",
        "  return img1\r\n",
        "\r\n",
        "class_labels = {'0':'normal', '1':'overlap'}\r\n",
        "\r\n",
        "def decode_prediction(pred):\r\n",
        "\r\n",
        "  predict = np.argmax(pred[0])\r\n",
        "  predict_label = class_labels[str(predict)]\r\n",
        "\r\n",
        "  return predict_label\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi72f49eguRo"
      },
      "source": [
        "import glob\r\n",
        "\r\n",
        "gc.collect()\r\n",
        "\r\n",
        "#model = keras.models.load_model('/content/drive/MyDrive/temp/txt_overlap_model1')\r\n",
        "\r\n",
        "#images = []\r\n",
        "images = glob.glob('/content/drive/MyDrive/binary/normal/*.png')\r\n",
        "images = images + glob.glob('/content/drive/MyDrive/binary/overlap/*.png')\r\n",
        "\r\n",
        "predictions = []\r\n",
        "\r\n",
        "for img in images:\r\n",
        "\r\n",
        "  image = preprocess_img(img)\r\n",
        "\r\n",
        "  predict = re_model.predict(image)\r\n",
        "\r\n",
        "  predict_label = decode_prediction(predict)\r\n",
        "\r\n",
        "  predictions.append(predict_label)\r\n",
        "\r\n",
        "  del image, predict, predict_label\r\n",
        "  gc.collect()\r\n",
        "\r\n",
        "print('Predicted {} samples.'.format(len(predictions)))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42FGexYwj7a9"
      },
      "source": [
        "plt.hist(predictions)\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4thn8Q80YwA"
      },
      "source": [
        "# -*- coding: utf-8 -*-\r\n",
        "\"\"\"\r\n",
        "Created on Tue Feb  2 17:17:12 2021\r\n",
        "\r\n",
        "@author: lawrence123\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "# Visualize object in image: Grad CAM\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow.keras as keras\r\n",
        "import cv2\r\n",
        "import imutils\r\n",
        "\r\n",
        "from keras import Model as Model\r\n",
        "\r\n",
        "# import the necessary packages\r\n",
        "\r\n",
        "class GradCAM():\r\n",
        "  def __init__(self, model, classIdx, layerName=None):\r\n",
        "    # store the model, the class index used to measure the class\r\n",
        "    # activation map, and the layer to be used when visualizing\r\n",
        "    # the class activation map\r\n",
        "    self.model = model\r\n",
        "    self.classIdx = classIdx\r\n",
        "    self.layerName = layerName\r\n",
        "    # if the layer name is None, attempt to automatically find\r\n",
        "    # the target output layer\r\n",
        "    if self.layerName == None:\r\n",
        "    \tself.layerName = self.find_target_layer()\r\n",
        "   \r\n",
        "  def find_target_layer(self):\r\n",
        "    # attempt to find the final convolutional layer in the network\r\n",
        "    # by looping over the layers of the network in reverse order\r\n",
        "    for layer in reversed(self.model.layers):\r\n",
        "    \t# check to see if the layer has a 4D output\r\n",
        "    \tif len(layer.output_shape) == 4:\r\n",
        "\t    \t\treturn layer.name\r\n",
        "\t\t# otherwise, we could not find a 4D layer so the GradCAM\r\n",
        "    # algorithm cannot be applied\r\n",
        "    raise ValueError(\"Could not find 4D layer. Cannot apply GradCAM.\")\r\n",
        "  \r\n",
        "  def compute_heatmap(self, image, eps=1e-8):\r\n",
        "    # construct our gradient model by supplying (1) the inputs\r\n",
        "    # to our pre-trained model, (2) the output of the (presumably)\r\n",
        "    # final 4D layer in the network, and (3) the output of the\r\n",
        "    # softmax activations from the model\r\n",
        "    gradModel = Model(\r\n",
        "      inputs=[self.model.inputs],\r\n",
        "      outputs=[self.model.get_layer(self.layerName).output, self.model.output])\r\n",
        "\r\n",
        "    # record operations for automatic differentiation\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "    # cast the image tensor to a float-32 data type, pass the\r\n",
        "    # image through the gradient model, and grab the loss\r\n",
        "    # associated with the specific class index\r\n",
        "      inputs = tf.cast(image, tf.float32)\r\n",
        "      (convOutputs, predictions) = gradModel(inputs)\r\n",
        "      loss = predictions[:, self.classIdx]\r\n",
        "    # use automatic differentiation to compute the gradients\r\n",
        "    grads = tape.gradient(loss, convOutputs)\r\n",
        "    # compute the guided gradients\r\n",
        "    castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\r\n",
        "    castGrads = tf.cast(grads > 0, \"float32\")\r\n",
        "    guidedGrads = castConvOutputs * castGrads * grads\r\n",
        "    # the convolution and guided gradients have a batch dimension\r\n",
        "    # (which we don't need) so let's grab the volume itself and\r\n",
        "    # discard the batch\r\n",
        "    convOutputs = convOutputs[0]\r\n",
        "    guidedGrads = guidedGrads[0]\r\n",
        "\r\n",
        "    # compute the average of the gradient values, and using them\r\n",
        "    # as weights, compute the ponderation of the filters with\r\n",
        "    # respect to the weights\r\n",
        "    weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\r\n",
        "    cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\r\n",
        " \r\n",
        "    # grab the spatial dimensions of the input image and resize\r\n",
        "\t\t# the output class activation map to match the input image\r\n",
        "\t\t# dimensions\r\n",
        "    (w, h) = (image.shape[2], image.shape[1])\r\n",
        "    heatmap = cv2.resize(cam.numpy(), (w, h))\r\n",
        "\t\t# normalize the heatmap such that all values lie in the range\r\n",
        "\t\t# [0, 1], scale the resulting values to the range [0, 255],\r\n",
        "\t\t# and then convert to an unsigned 8-bit integer\r\n",
        "    numer = heatmap - np.min(heatmap)\r\n",
        "    denom = (heatmap.max() - heatmap.min()) + eps\r\n",
        "    heatmap = numer / denom\r\n",
        "    heatmap = (heatmap * 255).astype(\"uint8\")\r\n",
        "\t\t# return the resulting heatmap to the calling function\r\n",
        "    return heatmap\r\n",
        "\r\n",
        "  def overlay_heatmap(self, heatmap, image, alpha=0.5, colormap=cv2.COLORMAP_VIRIDIS):\r\n",
        "\t\t# apply the supplied color map to the heatmap and then\r\n",
        "\t\t# overlay the heatmap on the input image\r\n",
        "        heatmap = cv2.applyColorMap(heatmap, colormap)\r\n",
        "        output = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\r\n",
        "\t\t# return a 2-tuple of the color mapped heatmap and the output,\r\n",
        "\t\t# overlaid image\r\n",
        "        return (heatmap, output)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83fUkrxIDnS5"
      },
      "source": [
        "from keras.applications.resnet50 import decode_predictions\r\n",
        "\r\n",
        "preds = model.predict(img1)\r\n",
        "\r\n",
        "class_labels = {'0':'normal', '1':'overlap'}\r\n",
        "\r\n",
        "def decode_prediction(pred):\r\n",
        "\r\n",
        "  predict = np.argmax(pred[0])\r\n",
        "  predict_label = class_labels[str(predict)]\r\n",
        "\r\n",
        "  return predict_label\r\n",
        "\r\n",
        "i = np.argmax(preds[0])\r\n",
        "# decode the ImageNet predictions to obtain the human-readable label\r\n",
        "decoded = decode_prediction(preds)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "(imagenetID, label, prob) = decoded[0][0]\r\n",
        "label = \"{}: {:.2f}%\".format(label, prob * 100)\r\n",
        "print(\"[INFO] {}\".format(label))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv6q5kBcEHsV"
      },
      "source": [
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSmj2zwGKrbc"
      },
      "source": [
        "i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di7UR0rMKzcJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
