{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_txt_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMrFgJdPgti1/ab6Ho6odXX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurence-lin/Working-files/blob/main/test_txt_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlkhgeaMjekw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e6f5755-9a17-4d1a-86f2-94c992bbf6ef"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import glob\r\n",
        "import os\r\n",
        "\r\n",
        "from tensorflow.keras.applications import ResNet50\r\n",
        "import cv2\r\n",
        "\r\n",
        "import tensorflow.keras as keras\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras import layers\r\n",
        "import tensorflow as tf\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import time\r\n",
        "import gc\r\n",
        "\r\n",
        "import torch\r\n",
        "import torchvision\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "print('Library imported.')\r\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Library imported.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0brFuVJBjhHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0262b333-7893-4636-ae85-5465981392cf"
      },
      "source": [
        "from google.colab import drive\r\n",
        "\r\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmFNRdh1jqLn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f97beb2-ede7-4e4e-8727-0419eab6bf48"
      },
      "source": [
        "# HYPER PARAMETERS SETTING\r\n",
        "import pickle\r\n",
        "\r\n",
        "# Calculate width-height ratio to resize image with same scaling\r\n",
        "IMG_PATH = glob.glob('/content/drive/MyDrive/binary_data/train/normal/*.png')\r\n",
        "MODEL_PATH = '/content/drive/MyDrive/pretrained_txt_overlap_model/resnet34_new.pickle'\r\n",
        "\r\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\r\n",
        "print('Current device: ', device)\r\n",
        "\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current device:  cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJ6aLkm5JaZz",
        "outputId": "e2725194-9bb9-4455-b211-e6dbd10ca891"
      },
      "source": [
        "from PIL import Image\r\n",
        "# Load model and dataset\r\n",
        "\r\n",
        "# Load pre-trained model\r\n",
        "with open(MODEL_PATH, 'rb') as f:\r\n",
        "  pre_model = pickle.load(f)\r\n",
        "\r\n",
        "print('Pre-trained model loaded.')\r\n",
        "\r\n",
        "# Data-transformer\r\n",
        "# Define data augmentation and data loader\r\n",
        "from torchvision import transforms\r\n",
        "\r\n",
        "# Define data augmentation methods\r\n",
        "data_preprocess = transforms.Compose([\r\n",
        "      transforms.ToTensor(),\r\n",
        "      transforms.Normalize(0.456, 0.225)\r\n",
        "    ])\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# Preprocess image for PyTorch data architecture\r\n",
        "def process_for_model(img):\r\n",
        "  '''\r\n",
        "  Process image array for PyTorch model\r\n",
        "  img: image path string\r\n",
        "  return: Tensor image prepared to input to the model\r\n",
        "  '''\r\n",
        "  img = Image.open(img).convert('RGB')\r\n",
        "  img = data_preprocess(img) # remember to do data preprocessing as in the training stage!! This strongly influence the testing performance\r\n",
        "  img = img.to(device)\r\n",
        "  img = img.view(1, 3, 889, 929)\r\n",
        "\r\n",
        "  return img\r\n",
        "\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pre-trained model loaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp_hgp2eMuxr"
      },
      "source": [
        "\r\n",
        "def compare_list(y_pred, y_true):\r\n",
        "  '''\r\n",
        "  Compare prediction and true label of two list\r\n",
        "  '''\r\n",
        "\r\n",
        "  result = [1 if (x1 == x2) else 0 for x1, x2 in zip(y_pred, y_true)]\r\n",
        "  return result\r\n",
        "\r\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8TM8XarKMfI",
        "outputId": "99fed74b-d0c8-4d5f-d250-e62fc0755e3c"
      },
      "source": [
        "# Test pre-trained model performance\r\n",
        "\r\n",
        "print('Test pre-trained model performance...')\r\n",
        "\r\n",
        "# Test the model performance\r\n",
        "\r\n",
        "normal_path = glob.glob('/content/drive/MyDrive/binary_data/val/normal/*.png')\r\n",
        "overlap_path = glob.glob('/content/drive/MyDrive/binary_data/val/overlap/*.png')\r\n",
        "\r\n",
        "test_path = normal_path + overlap_path\r\n",
        "labels = [1 if 'add' in file else 0 for file in test_path]\r\n",
        "\r\n",
        "label_dict = {0:'normal', 1:'overlap'}\r\n",
        "\r\n",
        "print('Start testing prediction...')\r\n",
        "\r\n",
        "predictions = []\r\n",
        "for i in range(len(test_path)):\r\n",
        "  img = process_for_model(test_path[i]) # data preprocessing\r\n",
        "\r\n",
        "  predict = pre_model(img).cpu().detach().numpy().argmax() # make prediction\r\n",
        "  predictions.append(predict)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "print('Finish testing prediction.')\r\n",
        "\r\n",
        "compare_result = np.array(compare_list(predictions, labels))\r\n",
        "accuracy = compare_result.sum() / len(compare_result)\r\n",
        "\r\n",
        "\r\n",
        "print('Overall accuracy: ', accuracy)\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test pre-trained model performance...\n",
            "Start testing prediction...\n",
            "Finish testing prediction.\n",
            "Overall accuracy:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9CPTiOxPUhU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}