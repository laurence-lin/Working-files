{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_txt_model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPKyuu35d4cRBBwZmBWwDa2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurence-lin/Working-files/blob/main/train_txt_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcwMODEZmnhT"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import os\r\n",
        "\r\n",
        "from tensorflow.keras.applications import ResNet50\r\n",
        "import cv2\r\n",
        "\r\n",
        "import tensorflow.keras as keras\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras import layers\r\n",
        "import tensorflow as tf\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import time\r\n",
        "import gc\r\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BOHP_2Dm2hg",
        "outputId": "bb4e51ee-edfd-4b33-db52-7be95d67650b"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Feb  3 01:21:02 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IRUT8Uiqm8-L",
        "outputId": "ae8f8b82-c841-4af3-c17c-28c91470a445"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlSRwmkXnD8c",
        "outputId": "53467e2e-39c6-4065-c5e8-ae20155b11e8"
      },
      "source": [
        "from google.colab import drive\r\n",
        "\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWu05V2Pnhb7"
      },
      "source": [
        "image_path = '/content/drive/MyDrive/binary'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76-xoJ6Dxv3Z"
      },
      "source": [
        "# HYPER PARAMETERS SETTING\r\n",
        "\r\n",
        "IMAGE_WIDTH = 500\r\n",
        "IMAGE_HEIGHT = 600\r\n",
        "BATCH_SIZE = 16\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OA2Oq_96ntWu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6707c999-f6c2-468a-d1e3-80c3db27d21d"
      },
      "source": [
        "\r\n",
        "train_loader = keras.preprocessing.image_dataset_from_directory(\r\n",
        "    image_path,\r\n",
        "    label_mode = 'categorical',\r\n",
        "    validation_split = 0.2,\r\n",
        "    color_mode = 'rgb',\r\n",
        "    subset = 'training',\r\n",
        "    image_size = (IMAGE_WIDTH, IMAGE_HEIGHT),\r\n",
        "    batch_size = BATCH_SIZE,\r\n",
        "    seed = 123\r\n",
        "    )\r\n",
        "\r\n",
        "valid_loader = keras.preprocessing.image_dataset_from_directory(\r\n",
        "    image_path,\r\n",
        "    label_mode = 'categorical',\r\n",
        "    validation_split = 0.2,\r\n",
        "    color_mode = 'rgb',\r\n",
        "    subset = 'validation',\r\n",
        "    image_size = (IMAGE_WIDTH, IMAGE_HEIGHT),\r\n",
        "    batch_size = BATCH_SIZE,\r\n",
        "    seed = 123\r\n",
        "    )\r\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400 files belonging to 3 classes.\n",
            "Using 320 files for training.\n",
            "Found 400 files belonging to 3 classes.\n",
            "Using 80 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiIDjAzqoXOx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5839f30-bdf6-4361-d8f3-6447fa21943b"
      },
      "source": [
        "# Define model\r\n",
        "\r\n",
        "FREEZE_LAYER = 2\r\n",
        "classes = 2\r\n",
        "\r\n",
        "# Define model\r\n",
        "base_model = ResNet50(\r\n",
        "    include_top = False,\r\n",
        "    input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, 3),\r\n",
        "    weights = 'imagenet'\r\n",
        "    #classes = 2\r\n",
        "    )\r\n",
        "\r\n",
        "def build_model(base_model):\r\n",
        "    # Build custom model for the pre-trained resnet50\r\n",
        "    \r\n",
        "    x = base_model.output\r\n",
        "    x = keras.layers.Flatten()(x)\r\n",
        "    x = keras.layers.Dropout(0.5)(x)\r\n",
        "    \r\n",
        "    output = keras.layers.Dense(classes, activation = 'softmax', name='softmax')(x)\r\n",
        "    \r\n",
        "    final_model = keras.Model(inputs = base_model.input, \r\n",
        "                        outputs = output)\r\n",
        "    \r\n",
        "    for layer in final_model.layers[:FREEZE_LAYER]:\r\n",
        "        layer.trainable = False\r\n",
        "        \r\n",
        "    for layer in final_model.layers[FREEZE_LAYER:]:\r\n",
        "        layer.trainable = True\r\n",
        "    \r\n",
        "    return final_model\r\n",
        "    \r\n",
        "model = build_model(base_model)\r\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okDzdAhcoaWv",
        "outputId": "03ed8e06-2af1-463e-a635-43efb066af5e"
      },
      "source": [
        "model.compile(\r\n",
        "    optimizer = keras.optimizers.Adam(1e-5),\r\n",
        "    loss = tf.losses.BinaryCrossentropy(from_logits = True),\r\n",
        "    metrics=['accuracy']\r\n",
        "    )\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 500, 600, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 506, 606, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 250, 300, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 250, 300, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 250, 300, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 252, 302, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 125, 150, 64) 0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 125, 150, 64) 4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 125, 150, 64) 256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 125, 150, 64) 0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 125, 150, 64) 36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 125, 150, 64) 256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 125, 150, 64) 0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 125, 150, 256 16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 125, 150, 256 16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 125, 150, 256 1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 125, 150, 256 1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 125, 150, 256 0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 125, 150, 256 0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 125, 150, 64) 16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 125, 150, 64) 256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 125, 150, 64) 0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 125, 150, 64) 36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 125, 150, 64) 256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 125, 150, 64) 0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 125, 150, 256 16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 125, 150, 256 1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 125, 150, 256 0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 125, 150, 256 0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 125, 150, 64) 16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 125, 150, 64) 256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 125, 150, 64) 0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 125, 150, 64) 36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 125, 150, 64) 256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 125, 150, 64) 0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 125, 150, 256 16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 125, 150, 256 1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 125, 150, 256 0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 125, 150, 256 0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 63, 75, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 63, 75, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 63, 75, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 63, 75, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 63, 75, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 63, 75, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 63, 75, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 63, 75, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 63, 75, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 63, 75, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 63, 75, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 63, 75, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 63, 75, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 63, 75, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 63, 75, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 63, 75, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 63, 75, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 63, 75, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 63, 75, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 63, 75, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 63, 75, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 63, 75, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 63, 75, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 63, 75, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 63, 75, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 63, 75, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 63, 75, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 63, 75, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 63, 75, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 63, 75, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 63, 75, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 63, 75, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 63, 75, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 63, 75, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 63, 75, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 63, 75, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 63, 75, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 63, 75, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 63, 75, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 63, 75, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 63, 75, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 63, 75, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 32, 38, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 32, 38, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 32, 38, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 32, 38, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 32, 38, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 32, 38, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 32, 38, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 32, 38, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 32, 38, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 32, 38, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 32, 38, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 32, 38, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 32, 38, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 32, 38, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 32, 38, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 32, 38, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 32, 38, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 32, 38, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 32, 38, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 32, 38, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 32, 38, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 32, 38, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 32, 38, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 32, 38, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 32, 38, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 32, 38, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 32, 38, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 32, 38, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 32, 38, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 32, 38, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 32, 38, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 32, 38, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 32, 38, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 32, 38, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 32, 38, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 32, 38, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 32, 38, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 32, 38, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 32, 38, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 32, 38, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 32, 38, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 32, 38, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 32, 38, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 32, 38, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 32, 38, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 32, 38, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 32, 38, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 32, 38, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 32, 38, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 32, 38, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 32, 38, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 32, 38, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 32, 38, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 32, 38, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 32, 38, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 32, 38, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 32, 38, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 32, 38, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 32, 38, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 32, 38, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 32, 38, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 32, 38, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 16, 19, 512)  524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 16, 19, 512)  2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 16, 19, 512)  0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 16, 19, 512)  2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 16, 19, 512)  2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 16, 19, 512)  0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 16, 19, 2048) 2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 16, 19, 2048) 1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 16, 19, 2048) 8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 16, 19, 2048) 8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 16, 19, 2048) 0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 16, 19, 2048) 0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 16, 19, 512)  1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 16, 19, 512)  2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 16, 19, 512)  0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 16, 19, 512)  2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 16, 19, 512)  2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 16, 19, 512)  0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 16, 19, 2048) 1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 16, 19, 2048) 8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 16, 19, 2048) 0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 16, 19, 2048) 0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 16, 19, 512)  1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 16, 19, 512)  2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 16, 19, 512)  0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 16, 19, 512)  2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 16, 19, 512)  2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 16, 19, 512)  0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 16, 19, 2048) 1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 16, 19, 2048) 8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 16, 19, 2048) 0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 16, 19, 2048) 0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 622592)       0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 622592)       0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Dense)                 (None, 2)            1245186     dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 24,832,898\n",
            "Trainable params: 24,779,778\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 960
        },
        "id": "b7AtP7-sob0e",
        "outputId": "5ace2c48-9f79-4908-c4a1-c678069dcaeb"
      },
      "source": [
        "model.fit(\r\n",
        "    train_loader,\r\n",
        "    validation_data = valid_loader,\r\n",
        "    epochs = 10\r\n",
        "    )"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-e53a582c1365>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:756 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:1608 binary_crossentropy\n        K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:4979 binary_crossentropy\n        return nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:174 sigmoid_cross_entropy_with_logits\n        (logits.get_shape(), labels.get_shape()))\n\n    ValueError: logits and labels must have the same shape ((None, 2) vs (None, 3))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKlZH-VxuqsE"
      },
      "source": [
        "# Save model on drive \r\n",
        "model.save('txt_overlap_model1')\r\n",
        "!cp -r txt_overlap_model1 '/content/drive/MyDrive/binary/txt_overlap_model1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF_8G7Dxh9YB"
      },
      "source": [
        "\r\n",
        "\r\n",
        "def preprocess_img(img):\r\n",
        "  '''\r\n",
        "  img: input image directory\r\n",
        "  output: processed image array could feed to predictive model\r\n",
        "\r\n",
        "  '''\r\n",
        "\r\n",
        "  img1 = plt.imread(img)\r\n",
        "  img1 = cv2.resize(img1, (IMAGE_HEIGHT, IMAGE_WIDTH))\r\n",
        "  img1 = cv2.cvtColor(img1, cv2.COLOR_RGBA2RGB)\r\n",
        "  img1 = np.expand_dims(img1, axis = 0)\r\n",
        "\r\n",
        "  return img1\r\n",
        "\r\n",
        "class_labels = {'0':'normal', '1':'overlap'}\r\n",
        "\r\n",
        "def decode_prediction(pred):\r\n",
        "\r\n",
        "  predict = np.argmax(pred[0])\r\n",
        "  predict_label = class_labels[str(predict)]\r\n",
        "\r\n",
        "  return predict_label\r\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi72f49eguRo",
        "outputId": "54c6e34b-0b36-4fc5-e618-32d8d9d150e0"
      },
      "source": [
        "import glob\r\n",
        "\r\n",
        "model = keras.models.load_model('/content/drive/MyDrive/binary/txt_overlap_model1')\r\n",
        "\r\n",
        "images = glob.glob('/content/drive/MyDrive/binary/normal/*.png')\r\n",
        "images = images + glob.glob('/content/drive/MyDrive/binary/overlap/*.png')\r\n",
        "\r\n",
        "predictions = []\r\n",
        "\r\n",
        "for img in images:\r\n",
        "\r\n",
        "  image = preprocess_img(img)\r\n",
        "\r\n",
        "  predict = model.predict(image)\r\n",
        "\r\n",
        "  predict_label = decode_prediction(predict)\r\n",
        "\r\n",
        "  predictions.append(predict_label)\r\n",
        "\r\n",
        "print('Predicted {} samples.'.format(len(predictions)))\r\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted 400 samples.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "42FGexYwj7a9",
        "outputId": "67c62dd8-0610-4e7b-86c0-ec564dc06fbc"
      },
      "source": [
        "plt.hist(predictions[:])\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4thn8Q80YwA"
      },
      "source": [
        "# -*- coding: utf-8 -*-\r\n",
        "\"\"\"\r\n",
        "Created on Tue Feb  2 17:17:12 2021\r\n",
        "\r\n",
        "@author: lawrence123\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "# Visualize object in image: Grad CAM\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow.keras as keras\r\n",
        "import cv2\r\n",
        "import imutils\r\n",
        "\r\n",
        "from keras import Model as Model\r\n",
        "\r\n",
        "# import the necessary packages\r\n",
        "\r\n",
        "class GradCAM():\r\n",
        "  def __init__(self, model, classIdx, layerName=None):\r\n",
        "    # store the model, the class index used to measure the class\r\n",
        "    # activation map, and the layer to be used when visualizing\r\n",
        "    # the class activation map\r\n",
        "    self.model = model\r\n",
        "    self.classIdx = classIdx\r\n",
        "    self.layerName = layerName\r\n",
        "    # if the layer name is None, attempt to automatically find\r\n",
        "    # the target output layer\r\n",
        "    if self.layerName == None:\r\n",
        "    \tself.layerName = self.find_target_layer()\r\n",
        "   \r\n",
        "  def find_target_layer(self):\r\n",
        "    # attempt to find the final convolutional layer in the network\r\n",
        "    # by looping over the layers of the network in reverse order\r\n",
        "    for layer in reversed(self.model.layers):\r\n",
        "    \t# check to see if the layer has a 4D output\r\n",
        "    \tif len(layer.output_shape) == 4:\r\n",
        "\t    \t\treturn layer.name\r\n",
        "\t\t# otherwise, we could not find a 4D layer so the GradCAM\r\n",
        "    # algorithm cannot be applied\r\n",
        "    raise ValueError(\"Could not find 4D layer. Cannot apply GradCAM.\")\r\n",
        "  \r\n",
        "  def compute_heatmap(self, image, eps=1e-8):\r\n",
        "    # construct our gradient model by supplying (1) the inputs\r\n",
        "    # to our pre-trained model, (2) the output of the (presumably)\r\n",
        "    # final 4D layer in the network, and (3) the output of the\r\n",
        "    # softmax activations from the model\r\n",
        "    gradModel = Model(\r\n",
        "      inputs=[self.model.inputs],\r\n",
        "      outputs=[self.model.get_layer(self.layerName).output, self.model.output])\r\n",
        "\r\n",
        "    # record operations for automatic differentiation\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "    # cast the image tensor to a float-32 data type, pass the\r\n",
        "    # image through the gradient model, and grab the loss\r\n",
        "    # associated with the specific class index\r\n",
        "      inputs = tf.cast(image, tf.float32)\r\n",
        "      (convOutputs, predictions) = gradModel(inputs)\r\n",
        "      loss = predictions[:, self.classIdx]\r\n",
        "    # use automatic differentiation to compute the gradients\r\n",
        "    grads = tape.gradient(loss, convOutputs)\r\n",
        "    # compute the guided gradients\r\n",
        "    castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\r\n",
        "    castGrads = tf.cast(grads > 0, \"float32\")\r\n",
        "    guidedGrads = castConvOutputs * castGrads * grads\r\n",
        "    # the convolution and guided gradients have a batch dimension\r\n",
        "    # (which we don't need) so let's grab the volume itself and\r\n",
        "    # discard the batch\r\n",
        "    convOutputs = convOutputs[0]\r\n",
        "    guidedGrads = guidedGrads[0]\r\n",
        "\r\n",
        "    # compute the average of the gradient values, and using them\r\n",
        "    # as weights, compute the ponderation of the filters with\r\n",
        "    # respect to the weights\r\n",
        "    weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\r\n",
        "    cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\r\n",
        " \r\n",
        "    # grab the spatial dimensions of the input image and resize\r\n",
        "\t\t# the output class activation map to match the input image\r\n",
        "\t\t# dimensions\r\n",
        "    (w, h) = (image.shape[2], image.shape[1])\r\n",
        "    heatmap = cv2.resize(cam.numpy(), (w, h))\r\n",
        "\t\t# normalize the heatmap such that all values lie in the range\r\n",
        "\t\t# [0, 1], scale the resulting values to the range [0, 255],\r\n",
        "\t\t# and then convert to an unsigned 8-bit integer\r\n",
        "    numer = heatmap - np.min(heatmap)\r\n",
        "    denom = (heatmap.max() - heatmap.min()) + eps\r\n",
        "    heatmap = numer / denom\r\n",
        "    heatmap = (heatmap * 255).astype(\"uint8\")\r\n",
        "\t\t# return the resulting heatmap to the calling function\r\n",
        "    return heatmap\r\n",
        "\r\n",
        "  def overlay_heatmap(self, heatmap, image, alpha=0.5, colormap=cv2.COLORMAP_VIRIDIS):\r\n",
        "\t\t# apply the supplied color map to the heatmap and then\r\n",
        "\t\t# overlay the heatmap on the input image\r\n",
        "        heatmap = cv2.applyColorMap(heatmap, colormap)\r\n",
        "        output = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\r\n",
        "\t\t# return a 2-tuple of the color mapped heatmap and the output,\r\n",
        "\t\t# overlaid image\r\n",
        "        return (heatmap, output)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83fUkrxIDnS5"
      },
      "source": [
        "from keras.applications.resnet50 import decode_predictions\r\n",
        "\r\n",
        "preds = model.predict(img1)\r\n",
        "\r\n",
        "class_labels = {'0':'normal', '1':'overlap'}\r\n",
        "\r\n",
        "def decode_prediction(pred):\r\n",
        "\r\n",
        "  predict = np.argmax(pred[0])\r\n",
        "  predict_label = class_labels[str(predict)]\r\n",
        "\r\n",
        "  return predict_label\r\n",
        "\r\n",
        "i = np.argmax(preds[0])\r\n",
        "# decode the ImageNet predictions to obtain the human-readable label\r\n",
        "decoded = decode_prediction(preds)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "(imagenetID, label, prob) = decoded[0][0]\r\n",
        "label = \"{}: {:.2f}%\".format(label, prob * 100)\r\n",
        "print(\"[INFO] {}\".format(label))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv6q5kBcEHsV"
      },
      "source": [
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSmj2zwGKrbc"
      },
      "source": [
        "i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di7UR0rMKzcJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}